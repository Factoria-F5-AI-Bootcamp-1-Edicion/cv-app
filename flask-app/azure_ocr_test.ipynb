{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.ai.formrecognizer import DocumentModelAdministrationClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from docx import Document\n",
    "from pyresparser import ResumeParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar el cliente de Form Recognizer\n",
    "endpoint = os.getenv(\"AZURE_FORM_RECOGNIZER_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_FORM_RECOGNIZER_KEY\")\n",
    "model_id = \"model_1\"\n",
    "\n",
    "credential = AzureKeyCredential(key)\n",
    "document_model_admin_client = DocumentModelAdministrationClient(endpoint, credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_analysis(doc_name):\n",
    "    try:\n",
    "        with open(doc_name, \"rb\") as fd:\n",
    "            document = fd.read()\n",
    "        \n",
    "        document_analysis_client = DocumentAnalysisClient(\n",
    "            endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "        \n",
    "        poller = document_analysis_client.begin_analyze_document (\"prebuilt-read\", document)\n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract text from OCR result\n",
    "        extracted_text = str(result.content)\n",
    "        \n",
    "        return {'status': 'success', 'extracted_text': extracted_text}\n",
    "    except Exception as e:\n",
    "        return {'status': 'error', 'message': str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'extracted_text': 'machine learning ia diseño gráfico-web\\nSoy Javier Inglés Sánchez, tengo una larga carrera en el sector editorial como diseñador gráfico y maquetador. He dado un giro a mi trayectoria centrándome ahora en otro diseño, pero esta vez el relacionado con el apasionante mundo de los datos y la inteligencia artificial.\\neducación\\nFP2 Artes Gráficas especialidad Diseño Gráfico. BUP y COU en Colegio España Santa\\nEulalia. Certificados SEPE: en\\nConfección y Publicación\\nde páginas web. Técnico en\\nGestión Ambiental. Interfaces y experiencia de usuario (UI Y UX)\\nCMS-Ecommerce. PHP y MySQL (Bases de datos). Inglés, nivel medio escrito y hablado. Buena ortografía y redacción de textos.\\nexperiencia profesional\\nskills\\nPython BBDD\\nJyra/Trello Miro\\nJupyter\\nGithub\\nGit\\nSQL Streamlit\\nHTML5\\nCSS3\\nJavaScript Visual Studio C.\\nData Analyst-Data Scientist. Actualmente realizando un\\nBootcamp de Inteligencia\\nArtificial en Factoría F5.\\nRealizando proyectos en\\nMachine Learning y Deep Learning. Ingeniería y Análisis de Datos, Desarrollo en python, Clasificación, Regresión, NLP (Detección de mensajes de odio), Reconocimiento Facial. Detección de objetos en imágenes.\\nSublime Text\\nFigma\\nMarvel app\\nSketch\\nXD\\nPhotoshop\\nIllustrator\\nInDesign\\nQuarkxpress\\nPremier\\njavier inglés\\ncontacto\\nManzanares el Real (Madrid) www.linkedin.com/in/javier-ingles 606 19 89 98 javieringles73@gmail.com https://github.com/Javingles\\nOtras aptitudes\\nMicrosoft Azure, Scikit-learn, Matplotlib, Numpy, Linux (Ubuntu), Windows, Mac, WordPress, Comunicación. Cultura general.\\ndeep learning\\nsobre mi\\nexperiencia laboral\\n23 años trabajando como diseñador gráfico y\\nmaquetador en la Editorial\\nMPIB. Colaborando también en el departamento de\\neventos con realización de cartelería y corporativo. También como monitor de motocilcletas y automoviles en el Salón Vive La Moto y en el evento Test the Best SUV.\\nMe considero una persona creativa, con facilidad para el\\ntrabajo en equipo y con capacidad\\nde liderazgo. Con don de gentes y empatía. Dispuesto a seguir aprendiendo y creciendo profesionalmente.\\nInvolucrado en la tecnología\\neventos\\ndatos'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr = ocr_analysis('CV_Javier_Ingles_IA.pdf')\n",
    "ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"machine learning ia dise\\\\u00f1o gr\\\\u00e1fico-web\\\\nSoy Javier Ingl\\\\u00e9s S\\\\u00e1nchez, tengo una larga carrera en el sector editorial como dise\\\\u00f1ador gr\\\\u00e1fico y maquetador. He dado un giro a mi trayectoria centr\\\\u00e1ndome ahora en otro dise\\\\u00f1o, pero esta vez el relacionado con el apasionante mundo de los datos y la inteligencia artificial.\\\\neducaci\\\\u00f3n\\\\nFP2 Artes Gr\\\\u00e1ficas especialidad Dise\\\\u00f1o Gr\\\\u00e1fico. BUP y COU en Colegio Espa\\\\u00f1a Santa\\\\nEulalia. Certificados SEPE: en\\\\nConfecci\\\\u00f3n y Publicaci\\\\u00f3n\\\\nde p\\\\u00e1ginas web. T\\\\u00e9cnico en\\\\nGesti\\\\u00f3n Ambiental. Interfaces y experiencia de usuario (UI Y UX)\\\\nCMS-Ecommerce. PHP y MySQL (Bases de datos). Ingl\\\\u00e9s, nivel medio escrito y hablado. Buena ortograf\\\\u00eda y redacci\\\\u00f3n de textos.\\\\nexperiencia profesional\\\\nskills\\\\nPython BBDD\\\\nJyra/Trello Miro\\\\nJupyter\\\\nGithub\\\\nGit\\\\nSQL Streamlit\\\\nHTML5\\\\nCSS3\\\\nJavaScript Visual Studio C.\\\\nData Analyst-Data Scientist. Actualmente realizando un\\\\nBootcamp de Inteligencia\\\\nArtificial en Factor\\\\u00eda F5.\\\\nRealizando proyectos en\\\\nMachine Learning y Deep Learning. Ingenier\\\\u00eda y An\\\\u00e1lisis de Datos, Desarrollo en python, Clasificaci\\\\u00f3n, Regresi\\\\u00f3n, NLP (Detecci\\\\u00f3n de mensajes de odio), Reconocimiento Facial. Detecci\\\\u00f3n de objetos en im\\\\u00e1genes.\\\\nSublime Text\\\\nFigma\\\\nMarvel app\\\\nSketch\\\\nXD\\\\nPhotoshop\\\\nIllustrator\\\\nInDesign\\\\nQuarkxpress\\\\nPremier\\\\njavier ingl\\\\u00e9s\\\\ncontacto\\\\nManzanares el Real (Madrid) www.linkedin.com/in/javier-ingles 606 19 89 98 javieringles73@gmail.com https://github.com/Javingles\\\\nOtras aptitudes\\\\nMicrosoft Azure, Scikit-learn, Matplotlib, Numpy, Linux (Ubuntu), Windows, Mac, WordPress, Comunicaci\\\\u00f3n. Cultura general.\\\\ndeep learning\\\\nsobre mi\\\\nexperiencia laboral\\\\n23 a\\\\u00f1os trabajando como dise\\\\u00f1ador gr\\\\u00e1fico y\\\\nmaquetador en la Editorial\\\\nMPIB. Colaborando tambi\\\\u00e9n en el departamento de\\\\neventos con realizaci\\\\u00f3n de carteler\\\\u00eda y corporativo. Tambi\\\\u00e9n como monitor de motocilcletas y automoviles en el Sal\\\\u00f3n Vive La Moto y en el evento Test the Best SUV.\\\\nMe considero una persona creativa, con facilidad para el\\\\ntrabajo en equipo y con capacidad\\\\nde liderazgo. Con don de gentes y empat\\\\u00eda. Dispuesto a seguir aprendiendo y creciendo profesionalmente.\\\\nInvolucrado en la tecnolog\\\\u00eda\\\\neventos\\\\ndatos\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_string = json.dumps(ocr['extracted_text'])\n",
    "ocr_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DooFromash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DooFromash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# download stopwords if necessary\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# define stopwords list\n",
    "stop_words = set(stopwords.words('english', 'spanish'))\n",
    "\n",
    "# define function to clean text\n",
    "def clean_text(text):\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # replace \\n with a space\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\\\n', ' ', text)\n",
    "    # remove special characters, punctuation, and emojis\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # tokenize into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # join the words back into a string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning ia diseu00f1o gru00e1ficoweb soy javier inglu00e9s su00e1nchez tengo una larga carrera en el sector editorial como diseu00f1ador gru00e1fico maquetador dado un giro mi trayectoria centru00e1ndome ahora en otro diseu00f1o pero esta vez el relacionado con el apasionante mundo de los datos la inteligencia artificial educaciu00f3n fp2 artes gru00e1ficas especialidad diseu00f1o gru00e1fico bup cou en colegio espau00f1a santa eulalia certificados sepe en confecciu00f3n publicaciu00f3n de pu00e1ginas web tu00e9cnico en gestiu00f3n ambiental interfaces experiencia de usuario ui ux cmsecommerce php mysql bases de datos inglu00e9s nivel medio escrito hablado buena ortografu00eda redacciu00f3n de textos experiencia profesional skills python bbdd jyratrello miro jupyter github git sql streamlit html5 css3 javascript visual studio c data analystdata scientist actualmente realizando un bootcamp de inteligencia artificial en factoru00eda f5 realizando proyectos en machine learning deep learning ingenieru00eda anu00e1lisis de datos desarrollo en python clasificaciu00f3n regresiu00f3n nlp detecciu00f3n de mensajes de odio reconocimiento facial detecciu00f3n de objetos en imu00e1genes sublime text figma marvel app sketch xd photoshop illustrator indesign quarkxpress premier javier inglu00e9s contacto manzanares el real madrid wwwlinkedincominjavieringles 606 19 89 98 javieringles73gmailcom aptitudes microsoft azure scikitlearn matplotlib numpy linux ubuntu windows mac wordpress comunicaciu00f3n cultura general deep learning sobre mi experiencia laboral 23 au00f1os trabajando como diseu00f1ador gru00e1fico maquetador en la editorial mpib colaborando tambiu00e9n en el departamento de eventos con realizaciu00f3n de carteleru00eda corporativo tambiu00e9n como monitor de motocilcletas automoviles en el salu00f3n vive la moto en el evento test best suv considero una persona creativa con facilidad para el trabajo en equipo con capacidad de liderazgo con de gentes empatu00eda dispuesto seguir aprendiendo creciendo profesionalmente involucrado en la tecnologu00eda eventos datos'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = clean_text(ocr_string)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from skill_keywords import skills_list\n",
    "\n",
    "import spacy\n",
    "\n",
    "def extract_skills(ocr_string):\n",
    "    # Load the spaCy model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "\n",
    "    # Parse the text using spaCy\n",
    "    doc = nlp(ocr_string)\n",
    "\n",
    "    # Extract the skill keywords that are present in the text\n",
    "    skills = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() in skills_list:\n",
    "            skills.append(token.text.lower())\n",
    "\n",
    "    # Remove duplicate skills\n",
    "    skills = list(set(skills))\n",
    "    \n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wordpress',\n",
       " 'sql',\n",
       " 'github',\n",
       " 'ubuntu',\n",
       " 'indesign',\n",
       " 'editorial',\n",
       " 'jupyter',\n",
       " 'matplotlib',\n",
       " 'photoshop',\n",
       " 'ux',\n",
       " 'python',\n",
       " 'c',\n",
       " 'illustrator',\n",
       " 'visual',\n",
       " 'linux',\n",
       " 'numpy',\n",
       " 'javascript',\n",
       " 'php',\n",
       " 'mysql',\n",
       " 'html5',\n",
       " 'windows',\n",
       " 'sublime',\n",
       " 'sketch',\n",
       " 'ui']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = extract_skills(cleaned_text)\n",
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wordpress sql github ubuntu indesign editorial jupyter matplotlib photoshop ux python c illustrator visual linux numpy javascript php mysql html5 windows sublime sketch ui'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = ' '.join(skills)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from ftfy import fix_text\n",
    "\n",
    "def ngrams(string, n=3):\n",
    "    string = fix_text(string) # fix text\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower()\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stopw  = set(stopwords.words('english'))\n",
    "df =pd.read_csv('job_final.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       About company: Smart Food Safe Solutions Inc. ...\n",
       "1       Location Bangalore Experience Years Job Descri...\n",
       "2       Open Systems International, Inc. (OSI) www.osi...\n",
       "3       About Job Software Testing Engineer Job Descri...\n",
       "4       Location: Bangalore Experience: 6Years Skills ...\n",
       "                              ...                        \n",
       "1919    Skills Qualifications: Years experience Strong...\n",
       "1920    Job TH10519_13189 Posted on: 29th May, 2019Job...\n",
       "1921    Job Description spend percent lives buildings....\n",
       "1922    (Job Number: 1905027) Job Title â€“ Web Develo...\n",
       "1923    marry design engineering language ways produce...\n",
       "Name: test, Length: 1924, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test']=df['Job_Description'].apply(lambda x: ' '.join([word for word in str(x).split() if len(word)>2 and word not in (stopw)]))\n",
    "df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "test = (df['test'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getNearestN(query):\n",
    "  queryTFIDF_ = vectorizer.transform(query)\n",
    "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "  return distances, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = getNearestN(test)\n",
    "test = list(test) \n",
    "matches = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(indices):\n",
    "    dist=round(distances[i][0],2)\n",
    "  \n",
    "    temp = [dist]\n",
    "    matches.append(temp)\n",
    "    \n",
    "matches = pd.DataFrame(matches, columns=['Match confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Invert the distances and then scale them to a 0-100% range\n",
    "scaler = MinMaxScaler(feature_range=(0, 100))\n",
    "matches['Match confidence'] = scaler.fit_transform(1 - matches[['Match confidence']])\n",
    "\n",
    "# Format the Match confidence column to include the % sign and show no decimal places\n",
    "matches['Match confidence'] = matches['Match confidence'].map('{:.0f}%'.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185</td>\n",
       "      <td>Python Developer (1512)</td>\n",
       "      <td>MSC Software</td>\n",
       "      <td>97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>Python Developer</td>\n",
       "      <td>MSC Software</td>\n",
       "      <td>97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1417</td>\n",
       "      <td>WordPress Developer (1 to 3 years)</td>\n",
       "      <td>Ladybird Web Solution</td>\n",
       "      <td>94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1859</td>\n",
       "      <td>JavaScript Developer</td>\n",
       "      <td>Charmboard</td>\n",
       "      <td>94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>608</td>\n",
       "      <td>System Engineer</td>\n",
       "      <td>Collasys Global Services LLP</td>\n",
       "      <td>92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>556</td>\n",
       "      <td>Hiring for Web Developer -Javascript</td>\n",
       "      <td>IMC LLP</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Software Testing Engineer</td>\n",
       "      <td>Bloom Consulting Services</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1557</td>\n",
       "      <td>Consumer Banking Technology - UK Consumer Depo...</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>659</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1558</td>\n",
       "      <td>JavaScript Developer</td>\n",
       "      <td>Tabtor India</td>\n",
       "      <td>9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           Position  \\\n",
       "0    185                            Python Developer (1512)   \n",
       "1    203                                   Python Developer   \n",
       "2   1417                 WordPress Developer (1 to 3 years)   \n",
       "3   1859                               JavaScript Developer   \n",
       "4    608                                    System Engineer   \n",
       "5    556               Hiring for Web Developer -Javascript   \n",
       "6      8                          Software Testing Engineer   \n",
       "7   1557  Consumer Banking Technology - UK Consumer Depo...   \n",
       "8    659                                     Data Scientist   \n",
       "9   1558                               JavaScript Developer   \n",
       "\n",
       "                        Company match  \n",
       "0                  MSC Software   97%  \n",
       "1                  MSC Software   97%  \n",
       "2         Ladybird Web Solution   94%  \n",
       "3                    Charmboard   94%  \n",
       "4  Collasys Global Services LLP   92%  \n",
       "5                       IMC LLP   90%  \n",
       "6     Bloom Consulting Services   90%  \n",
       "7                 Goldman Sachs    9%  \n",
       "8                         Adobe    9%  \n",
       "9                  Tabtor India    9%  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['match']=matches['Match confidence']\n",
    "df1=df.sort_values('match', ascending= False)\n",
    "df1[['Position', 'Company','match']].head(10).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f5-nlp-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9414013409abcdc265fddd93c87e223936ad967fe1fba2634488d4561217921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
