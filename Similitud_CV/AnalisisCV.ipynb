{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47156c6e-b660-4d25-b7ac-7d11685f92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "import pdfminer\n",
    "import pandas as pd\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b08cf8-1456-4496-969e-5267f574351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    # Tokenización de palabras y eliminación de palabras vacías y signos de puntuación\n",
    "    stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words and word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "531d90d0-482f-4d0e-a637-65ccb55ffe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'tf', 'crear', 'matriz', 'la', 'es', 'este', 'características', 'usando', 'un']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def extract_keywords(text):\n",
    "    # Creación de la matriz de características usando TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([text])\n",
    "\n",
    "    # Extracción de las palabras clave con mayor TF-IDF score\n",
    "    feature_names = tfidf_vectorizer.vocabulary_\n",
    "    sorted_feature_names = sorted(feature_names, key=lambda x: feature_names[x], reverse=True)\n",
    "    keyword_indices = [list(feature_names.values()).index(feature_names[f]) for f in sorted_feature_names[:10]]\n",
    "    keywords = [sorted_feature_names[i] for i in keyword_indices]\n",
    "\n",
    "    return keywords\n",
    "\n",
    "text = \"Este es un ejemplo de texto para crear la matriz de características usando TF-IDF\"\n",
    "keywords = extract_keywords(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc163c3f-f561-4455-b285-ac55eb25f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(file_path):\n",
    "    output_string = io.StringIO()\n",
    "    with open(file_path, 'rb') as in_file:\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        codec = 'utf-8'\n",
    "        laparams = LAParams()\n",
    "        device = TextConverter(rsrcmgr, output_string, codec=codec, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.get_pages(in_file):\n",
    "            interpreter.process_page(page)\n",
    "        device.close()\n",
    "    text = output_string.getvalue()\n",
    "    output_string.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36cbac6c-236c-4e88-8548-4c45fb50ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['playing', 'works', 'upto', 'date', 'keras', 'around', 'giving', 'create', 'got', 'placed']\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "pdf_file = 'CV_Kalash.pdf'\n",
    "text = pdf_to_text(pdf_file)\n",
    "keywords = extract_keywords(text)\n",
    "print(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38890f6f-21cd-4eba-86ad-445aa2740670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preprocesar texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir todo a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Eliminar stopwords\n",
    "    stop_words = set(stopwords.words(\"English\"))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Unir palabras de nuevo en una sola cadena\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fce833e-8f37-418e-8ff2-2a16b57634b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer texto del PDF\n",
    "pdf_path = \"CV_Kalash.pdf\"\n",
    "pdf_text = extract_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7fcddef-2703-4e67-b106-65b21464b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo CSV con oferta de empleo\n",
    "csv_path = \"output.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1122a9b4-1f44-47f6-853b-c59343eab3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar texto de ambas fuentes de datos\n",
    "pdf_text = preprocess_text(pdf_text)\n",
    "csv_text = preprocess_text(\" \".join(df.iloc[:, 0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e1b4e23-8256-43cc-b2b6-41493e0334c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular similitud coseno\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform([pdf_text, csv_text])\n",
    "similarity_score = cosine_similarity(tfidf)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8148820-2f49-4e68-8cee-03d52fab853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud entre el texto del PDF y el archivo CSV es: 0.09793218795014397\n"
     ]
    }
   ],
   "source": [
    "print(\"La similitud entre el texto del PDF y el archivo CSV es:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10c45b-03f8-4d48-9bc1-45468d06cea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
